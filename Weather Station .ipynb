{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from matplotlib.dates import date2num\n",
    "\n",
    "def data_scrap(ID, date):\n",
    "\n",
    "    #Scrap weather data of given location and given period of time from websites\n",
    "    #date in a 1 by 3 string array: Month/Date/Year\n",
    "\n",
    "    data_temp=[]\n",
    "    str1 = 'https://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID='\n",
    "    str2 = '&day='\n",
    "    str3 = '&month='\n",
    "    str4 = '&year='\n",
    "    str5 = '&graphspan=day&format=1'\n",
    "    url = str1+ID+str2+date[1]+str3+date[0]+str4+date[2]+str5\n",
    "    response = urllib.request.urlopen(url)\n",
    "    cr=csv.reader(io.TextIOWrapper(response))\n",
    "    for row in cr:\n",
    "        if len(row)<= 1: continue\n",
    "        data_temp.append(row)\n",
    "\n",
    "    data = [[0 for i in range(len(data_temp[1][:])-3)] for j in range(len(data_temp))]\n",
    "\n",
    "    for i in range(len(data_temp)):\n",
    "        if i == 0:\n",
    "            data[0][:]=data_temp[0][0:len(data_temp[i][:])-2]\n",
    "        elif i > 0:\n",
    "            data[i][0]=datetime.strptime(data_temp[i][0], '%Y-%m-%d %H:%M:%S')\n",
    "            data[i][1:data_temp[0][:].index('WindDirection')]=tuple(float(list_item) for list_item in data_temp[i][1:data_temp[0][:].index('WindDirection')])\n",
    "            data[i][data_temp[0][:].index('WindDirection')] = data_temp[i][data_temp[0][:].index('WindDirection')]\n",
    "            data[i][data_temp[0][:].index('WindDirection')+1:data_temp[0][:].index('Conditions')] = tuple(float(list_item) for list_item in data_temp[i][data_temp[0][:].index('WindDirection')+1:data_temp[0][:].index('Conditions')])\n",
    "            data[i][data_temp[0][:].index('Conditions'):data_temp[0][:].index('Clouds')+1] = data_temp[i][data_temp[0][:].index('Conditions'):data_temp[0][:].index('Clouds')+1]\n",
    "            data[i][data_temp[0][:].index('Clouds')+1:len(data_temp[0][:])-2] = tuple(float(list_item) for list_item in data_temp[i][data_temp[0][:].index('Clouds')+1:len(data_temp[i][:])-3])\n",
    "\n",
    "    data_csv = [[0 for i in range(7)] for j in range(len(data))]\n",
    "\n",
    "    for i in range(len(data_temp)):\n",
    "        data_csv[i][0:2] = data[i][0:2]\n",
    "        data_csv[i][2] = data[i][3]\n",
    "        data_csv[i][3] = data[i][6]\n",
    "        data_csv[i][4:6] = data[i][8:10]\n",
    "        data_csv[i][6] = data[i][13]\n",
    "    \n",
    "    path = os.getcwd() + ID + '.csv'\n",
    "    with open(path,'w',newline='') as f:\n",
    "        csv_file = csv.writer(f, delimiter=',')\n",
    "        for row in data_csv:\n",
    "            csv_file.writerow(row)\n",
    "\n",
    "    return data_csv, csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findNearestDate(alist,date,delta):\n",
    "    #Binary search to find the nearest datetime within tolerance in a list given a specific date\n",
    "    \n",
    "    midpoint = (len(alist)-1)//2 \n",
    "    \n",
    "    if midpoint < 0:\n",
    "        return None\n",
    "    else:\n",
    "        if abs(alist[midpoint]-date) < delta:\n",
    "                return alist[midpoint]\n",
    "        else:\n",
    "                if date < alist[midpoint]:\n",
    "                    return findNearestDate(alist[0:midpoint],date,delta)\n",
    "                else:\n",
    "                    return findNearestDate(alist[midpoint+1:],date,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergeData(raw_date, CPM, date):\n",
    "    #Merge radiation data to weather data; raw_date and CPM are from radiation data\n",
    "    \n",
    "    delta = timedelta(minutes=5)\n",
    "    merge = [0 for i in range(len(date))]\n",
    "\n",
    "    for i in range (len(date)):\n",
    "        new_date = findNearestDate(raw_date,date[i],delta)\n",
    "        merge[i] = CPM[raw_date.index(new_date)]\n",
    "            \n",
    " \n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateCorrelationCoefficient(data_x, data_y):\n",
    "    # Correlation Coefficient:\n",
    "    #r = sum((x(i)-x_avg)*(y(i)-y_avg))/sqrt( sum( (x(i)-x_avg)^2 )*sum( (y(i)-y_avg)^2 ) )\n",
    "    #Variance = (standard deviation)^2\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    sum_xy = 0\n",
    "    x_var = 0\n",
    "    y_var = 0\n",
    "    x_avg = sum(data_x)/len(data_x)\n",
    "    y_avg = sum(data_y)/len(data_y)\n",
    "\n",
    "    for i in range(0,len(data_x)):\n",
    "        sum_xy += (data_x[i]-x_avg) * (data_y[i]-y_avg)\n",
    "        sum_x += (data_x[i]-x_avg)*(data_x[i]-x_avg)\n",
    "        sum_y += (data_y[i]-y_avg)*(data_y[i]-y_avg)\n",
    "    \n",
    "    x_var = np.sqrt(sum_x/(len(data_x)-1))\n",
    "    y_var = np.sqrt(sum_y/(len(data_y)-1))\n",
    "    r = sum_xy/np.sqrt(sum_x*sum_y)\n",
    "    return r, x_var, y_var,x_avg,y_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = ['5','19','2016']\n",
    "location = 'KCABERKE89'\n",
    "data, csv_file =data_scrap(location, start)\n",
    "        \n",
    "#Import data from LBL device\n",
    "L_date = []\n",
    "L_CPM = []\n",
    "line = 0\n",
    "url = 'http://radwatch.berkeley.edu/sites/default/files/dosenet/lbl.csv'\n",
    "response = urllib.request.urlopen(url)\n",
    "        \n",
    "reader=csv.reader(io.TextIOWrapper(response))\n",
    "for row in reader:\n",
    "    if line != 0:\n",
    "        L_date.append(datetime.strptime(row[0],'%Y-%m-%d %H:%M:%S'))\n",
    "        L_CPM.append(float(row[1]))\n",
    "    line += 1\n",
    "       \n",
    "#Import data from weather station\n",
    "date = []\n",
    "temperature = []\n",
    "pressure = []\n",
    "windSpeed = []\n",
    "humidity = []\n",
    "hourPrecep = []\n",
    "solarRadiation = []\n",
    "line = 0\n",
    "for row in data:\n",
    "    if line != 0:\n",
    "        date.append(row[0])\n",
    "        temperature.append(row[1])\n",
    "        pressure.append(row[2])\n",
    "        windSpeed.append(row[3])\n",
    "        humidity.append([4])\n",
    "        hourPrecep.append(row[5])\n",
    "        solarRadiation.append(row[6])\n",
    "    line += 1\n",
    "\n",
    "#Modify LBL data according to weather station\n",
    "delta = timedelta(minutes=5)\n",
    "min_date_index = L_date.index(findNearestDate(L_date, date[0],delta))\n",
    "max_date_index = L_date.index(findNearestDate(L_date, date[-1],delta))\n",
    "merge = mergeData(L_date[min_date_index:max_date_index+1], L_CPM[min_date_index:max_date_index+1], date)\n",
    "\n",
    "\n",
    "#Determine correlation coefficient between two sets of data (Temperature vs Pressure)\n",
    "r,t_var,p_var, t_avg, p_avg = calculateCorrelationCoefficient(temperature, pressure)\n",
    "slope = r*p_var/t_var\n",
    "intercept = p_avg-slope*t_avg\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(temperature,pressure, 'co', label=\"Temperature vs Pressure\")\n",
    "\n",
    "#Plot least sqaures fit function\n",
    "polynomial = np.poly1d([slope, intercept])\n",
    "fit = polynomial(temperature)\n",
    "plt.plot(temperature, fit, label=\"least squares fit\")\n",
    "\n",
    "\n",
    "#Test Case #2 determining correlation between temperature and radiation data\n",
    "r,t_var,l_var, t_avg, l_avg = calculateCorrelationCoefficient(temperature, L_CPM)\n",
    "slope = r*l_var/t_var\n",
    "intercept = l_avg-slope*t_avg\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(temperature,merge, 'co', label=\"Temperature vs radiation\")\n",
    "                \n",
    "#Plot least squares fit function\n",
    "polynomial = np.poly1d([slope, intercept])\n",
    "fit = polynomial(temperature)\n",
    "plt.plot(temperature, fit, label=\"least squares fit\") \n",
    "        \n",
    "#Plot each set of data against time\n",
    "fig, ax = plt.subplots(7, sharex=True)\n",
    "ax[0].plot(date2num(date),temperature,'r-o',label='Temperature')\n",
    "ax[1].plot(date2num(date),temperature,'r-o',label='Pressure')\n",
    "ax[2].plot(date2num(date),windSpeed,'r-o',label='Wind Speed')\n",
    "ax[3].plot(date2num(date),humidity,'r-o',label='Humidity')\n",
    "ax[4].plot(date2num(date),hourPrecep,'r-o',label='Hourly Precipitation')\n",
    "ax[5].plot(date2num(date),solarRadiation,'r-o',label = 'Solar Radiation')\n",
    "ax[6].plot(date2num(date),merge,'r-o',label = 'CPM')\n",
    "\n",
    "for i in range (7):\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "    ax[i].legend(handles, labels, loc = 0)\n",
    "\n",
    "ax[0].xaxis.set_major_locator(mdates.HourLocator())\n",
    "ax[0].xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "ax[0].xaxis.set_minor_locator(mdates.MinuteLocator())\n",
    "ax[0].set_xlim(date[0],date[-1])\n",
    "ax[0].fmt_xdata = mdates.DateFormatter('%Y-%m-%d %H:%M:%S')\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.show()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
