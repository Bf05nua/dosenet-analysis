{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoseNet Workshop (ワークショップ)\n",
    "=========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ノートブックをセットアップし、必要なすべてのPythonライブラリをインポートする\n",
    "# Setup notebook and import all needed python libraries\n",
    "\n",
    "# Embed plots in the body of the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats=['svg']\n",
    "\n",
    "# Standard csv and file io python libraries\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import dateutil\n",
    "\n",
    "# Library for loading data from a webpage (Python 2 and 3 compatible)\n",
    "from future.standard_library import install_aliases\n",
    "install_aliases()\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Main python library for mathematical calculations\n",
    "import numpy as np\n",
    "import statistics\n",
    "from math import log10, floor\n",
    "import math\n",
    "from scipy.stats.stats import pearsonr, spearmanr\n",
    "\n",
    "# Plotting related python libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Python libraries for manipulating dates and times as objects\n",
    "import time\n",
    "import datetime as dt\n",
    "from matplotlib.dates import date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method for importing DoseNet Data from the website\n",
    "def importDoseNetCSV(url):\n",
    "    response = urlopen(url)\n",
    "    reader = csv.reader(io.TextIOWrapper(response))  \n",
    "    datetime = []    \n",
    "    cpm = []\n",
    "    line = 0\n",
    "    for row in reader:\n",
    "        if line != 0:\n",
    "            datetime.append(dateutil.parser.parse(row[0]))\n",
    "            cpm.append(float(row[3]))\n",
    "        line += 1    \n",
    "        # Python syntax for line = line + 1 (+1 to current value for line)\n",
    "    return (datetime,cpm)\n",
    "\n",
    "def importLocalCSV(filepath, filename):\n",
    "    datetime = []               \n",
    "    cpm = []\n",
    "    line = 0                    \n",
    "        \n",
    "    file = os.path.join(filepath,filename)\n",
    "    with open(file) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if line != 0:       \n",
    "                datetime.append(dateutil.parser.parse(row[0]))     \n",
    "                cpm.append(float(row[3]))   \n",
    "            line = line + 1\n",
    "    return datetime, cpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     17,
     46
    ],
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# 指定された時間範囲内のデータを選択する方法\n",
    "# Method for selecting data within the specified time range \n",
    "def SelectDataTimeRange(start_time,stop_time,data,times):\n",
    "    if not start_time.tzinfo:\n",
    "        start_time = start_time.replace(tzinfo=times[0].tzinfo)\n",
    "    if not stop_time.tzinfo:\n",
    "        stop_time = stop_time.replace(tzinfo=times[0].tzinfo)\n",
    "\n",
    "    dataarray = np.array(data)\n",
    "    timesarray = np.array(times)\n",
    "\n",
    "    indices = np.where((timesarray>=start_time)&(timesarray<stop_time))\n",
    "    subdata  = dataarray[indices]\n",
    "    subdatatimes = timesarray[indices]\n",
    "   \n",
    "    return subdata, subdatatimes\n",
    "\n",
    "def GetMergedData(start_time,stop_time,data,times,tdelta):\n",
    "    if not start_time.tzinfo:\n",
    "        start_time = start_time.replace(tzinfo=times[0].tzinfo)\n",
    "    if not stop_time.tzinfo:\n",
    "        stop_time = stop_time.replace(tzinfo=times[0].tzinfo)\n",
    "\n",
    "    merged_times = []\n",
    "    merged_data = []\n",
    "    merged_errs = []\n",
    "\n",
    "    err_time = tdelta.total_seconds()/60\n",
    "    date_itr = start_time\n",
    "    while date_itr < stop_time:\n",
    "        next_time = date_itr+tdelta\n",
    "        sub_data, sub_times = SelectDataTimeRange(date_itr,next_time,data,times)\n",
    "        this_time = date_itr+tdelta/2\n",
    "        date_itr = next_time\n",
    "        if len(sub_data)==0:\n",
    "            merged_point = np.nan\n",
    "            point_err = np.nan\n",
    "        else:\n",
    "            merged_point = sum(sub_data)/len(sub_data)\n",
    "            point_err = np.sqrt(merged_point*err_time)/err_time\n",
    "        merged_data.append(merged_point)\n",
    "        merged_errs.append(point_err)\n",
    "        #merged_times.append(sub_times[int(len(sub_times)/2)])\n",
    "        merged_times.append(this_time)\n",
    "    return merged_data, merged_errs, merged_times\n",
    "\n",
    "def inTimeRange(time_string,tstart,tstop):\n",
    "    time = tstart - dt.timedelta(minutes=1)\n",
    "    if isinstance(time_string, str):\n",
    "        try:\n",
    "            time = parse(time_string)\n",
    "        except:\n",
    "            #print('{} Not a time!'.format(time_string))\n",
    "            return False\n",
    "    elif isinstance(time_string, dt.datetime):\n",
    "        time = time_string\n",
    "\n",
    "    # check that tzinfo is set for tz aware comparisons\n",
    "    if tstart.tzinfo==None:\n",
    "        tstart = tstart.replace(tzinfo=time.tzinfo)\n",
    "    if tstop.tzinfo==None:\n",
    "        tstop = tstop.replace(tzinfo=time.tzinfo)\n",
    "    #print('Checking {} > {} and < {} = {}'.format(time,tstart,tstop,(time > tstart and time < tstop)))\n",
    "    return (time > tstart and time < tstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     11,
     20,
     26,
     40
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Methods for plotting different types of data\n",
    "def PlotData(time, data, plot_title, ytitle):    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(time, data)\n",
    "    plt.ylabel(ytitle)                                     # label the y-axis\n",
    "    plt.title(plot_title)                                  # put a title!\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "def PlotCPM(cpm, time, plot_title):\n",
    "    PlotData(time, cpm, plot_title, 'Counts per Minute')\n",
    "\n",
    "def PlotWithErrors(data, data_err, time, plot_title):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(time, data)\n",
    "    plt.errorbar(time, data, yerr=data_err, fmt=\"none\")\n",
    "    plt.ylabel('Counts Per Minute')                        # label the y-axis\n",
    "    plt.title(plot_title)                                  # put a title!\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "\n",
    "def PlotHistogram(cpm, plot_title):\n",
    "    plt.hist(cpm,bins=32)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Counts Per Minute')\n",
    "    plt.title(plot_title)\n",
    "\n",
    "def PlotComparisonHistograms(plot_title, data1, label1, data2, label2, data3 = [], label3 = ''):\n",
    "    fig = plt.figure()\n",
    "    plt.hist(data1,bins=32, alpha = 0.6)\n",
    "    plt.hist(data2,bins=33, alpha = 0.6)\n",
    "    if len(data3):\n",
    "        plt.hist(data3, bins=34, alpha = 0.6)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Counts Per Minute')\n",
    "    plt.title(plot_title)\n",
    "    legend_labels = [label1, label2]\n",
    "    if len(data3):\n",
    "        legend_labels.append(label3)\n",
    "    plt.legend(legend_labels, loc='best')\n",
    "\n",
    "def PlotCorrelation(xdata,x_err,ydata,y_err,xlabel,ylabel):\n",
    "    plt.plot(xdata,ydata, 'bo')\n",
    "\n",
    "    #errors based on 1hr count collection time converted to counts-per-second\n",
    "    # fmt=\"none\" stops the plot from drawing lines connecting each point\n",
    "    plt.errorbar(xdata, ydata, xerr=x_err, yerr=y_err, fmt=\"none\")\n",
    "\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    title = '{} vs {}'.format(xlabel,ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method for pulling weather data from specified weather station\n",
    "def GetWeatherData(ID, date):\n",
    "    #Scrap weather data of given location and given period of time from websites\n",
    "    #ID is a string contains weather station ID\n",
    "    #date is a 1 by 3 string array: Month/Date/Year\n",
    "\n",
    "    data_temp=[] #Stores raw data from the weather station\n",
    "    str1 = 'https://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID='\n",
    "    str2 = '&day='\n",
    "    str3 = '&month='\n",
    "    str4 = '&year='\n",
    "    str5 = '&graphspan=day&format=1'\n",
    "    url = str1+ID+str2+date[1]+str3+date[0]+str4+date[2]+str5\n",
    "    #print(url)\n",
    "    response = urlopen(url)\n",
    "    #cr=csv.reader(response)\n",
    "    cr=csv.reader(io.TextIOWrapper(response))\n",
    "    for row in cr:\n",
    "        if len(row)<= 1: continue\n",
    "        data_temp.append(row)\n",
    "    \n",
    "    #Stores data with correct data type (datetime/string/double)\n",
    "    data = [[0 for i in range(len(data_temp[1][:])-3)] for j in range(len(data_temp))]\n",
    "    \n",
    "    for i in range(len(data_temp)):\n",
    "        if i == 0:\n",
    "            data[0][:]=data_temp[0][0:len(data_temp[i][:])-2]\n",
    "        elif i > 0:\n",
    "            data[i][0]=dt.datetime.strptime(data_temp[i][0], '%Y-%m-%d %H:%M:%S')\n",
    "            data[i][1:data_temp[0][:].index('WindDirection')]=tuple(float(list_item) for list_item in data_temp[i][1:data_temp[0][:].index('WindDirection')])\n",
    "            data[i][data_temp[0][:].index('WindDirection')] = data_temp[i][data_temp[0][:].index('WindDirection')]\n",
    "            data[i][data_temp[0][:].index('WindDirection')+1:data_temp[0][:].index('Conditions')] = tuple(float(list_item) for list_item in data_temp[i][data_temp[0][:].index('WindDirection')+1:data_temp[0][:].index('Conditions')])\n",
    "            data[i][data_temp[0][:].index('Conditions'):data_temp[0][:].index('Clouds')+1] = data_temp[i][data_temp[0][:].index('Conditions'):data_temp[0][:].index('Clouds')+1]\n",
    "            data[i][data_temp[0][:].index('Clouds')+1:len(data_temp[0][:])-2] = tuple(float('0'+list_item) for list_item in data_temp[i][data_temp[0][:].index('Clouds')+1:len(data_temp[i][:])-3])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def GetWeatherStationData(data):\n",
    "    #Import data from weather station\n",
    "    date = []\n",
    "    temperature = []\n",
    "    pressure = []\n",
    "    windSpeed = []\n",
    "    humidity = []\n",
    "    hourPrecep = []\n",
    "    solarRadiation = []\n",
    "    WindDirection = []\n",
    "    line = 0\n",
    "    for row in data:\n",
    "        #skip first row (row that specifies fields)\n",
    "        if line != 0:\n",
    "            date.append(row[0])\n",
    "            temperature.append(row[1])\n",
    "            pressure.append(row[3])\n",
    "            windSpeed.append(row[6])\n",
    "            humidity.append(row[8])\n",
    "            hourPrecep.append(row[9])\n",
    "            solarRadiation.append(row[13])\n",
    "            WindDirection.append(row[4])\n",
    "        line += 1\n",
    "    return date, temperature, pressure, humidity, hourPrecep\n",
    "\n",
    "def GetWeatherDataRange(location,nhours,tstart,tstop,data_type):\n",
    "    date_itr = tstart\n",
    "    times = []\n",
    "    wdata = []\n",
    "    werrs = []\n",
    "    data_index = -1\n",
    "    if data_type == 'Temp':\n",
    "        data_index = 1\n",
    "    elif data_type == 'Humid':\n",
    "        data_index = 8\n",
    "    elif data_type == 'Press':\n",
    "        data_index = 3\n",
    "    elif data_type == 'Rain':\n",
    "        data_index = 9\n",
    "    elif data_type == 'Rad':\n",
    "        data_index = 13\n",
    "\n",
    "    while date_itr < tstop:\n",
    "        date = [str(date_itr.month),str(date_itr.day),str(date_itr.year)]\n",
    "        data = GetWeatherData(location, date)\n",
    "        time_itr = date_itr\n",
    "        date_itr = date_itr+dt.timedelta(days=1)\n",
    "        if not data:\n",
    "            print('No weather data for {}'.format(date_itr))\n",
    "        while time_itr < date_itr:\n",
    "            time_next = time_itr+dt.timedelta(hours=nhours)\n",
    "            integration = [row for row in data if \\\n",
    "                            inTimeRange(row[0],time_itr,time_next)]\n",
    "            times.append(time_itr+dt.timedelta(hours=nhours)/2)\n",
    "            this_data = np.nan\n",
    "            time_itr = time_next\n",
    "            if len(integration)==0:\n",
    "                this_data = np.nan\n",
    "                data_err = np.nan\n",
    "            else:\n",
    "                this_data = np.mean(np.asarray([x[data_index] for x in integration]))\n",
    "                data_err = np.var(np.asarray([x[data_index] for x in integration]))\n",
    "                data_err = np.sqrt(data_err)\n",
    "            wdata.append(this_data)\n",
    "            werrs.append(data_err)\n",
    "\n",
    "    return times,wdata,werrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DoseNet data from all stations in our network is available through the website. There are interactive graphs of the data on the weibsite, but to explore further, the raw data can be downloaded and analyzed directly. Here we will look at how the radiation rate is varying at an example station and compare several locations with eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_etch = 'https://radwatch.berkeley.edu/sites/default/files/dosenet/etch.csv' \n",
    "datetime_etch, cpm_etch = importDoseNetCSV(url_etch)\n",
    "url_jp = 'https://radwatch.berkeley.edu/sites/default/files/dosenet/koriyama_ch.csv' \n",
    "datetime_jp, cpm_jp = importDoseNetCSV(url_jp)\n",
    "url_norra = 'https://radwatch.berkeley.edu/sites/default/files/dosenet/norrareal.csv' \n",
    "datetime_norra, cpm_norra = importDoseNetCSV(url_norra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCPM(cpm_etch, datetime_etch, 'Etcheverry DoseNet Measurements vs Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCPM(cpm_jp, datetime_jp, 'Koriyama City DoseNet Measurements vs Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotHistogram(cpm_etch,'Etcheverry DoseNet Measurements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you think Berkeley and Koriyama City will compare? \n",
    "\n",
    "Will they have similar dose-rates? \n",
    "\n",
    "Why might they be different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotComparisonHistograms('DoseNet measurements',cpm_etch,'Berkeley, CA',cpm_jp,'Koriyama City, Japan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will Berkeley and Koriyama City compare with other places around the world?\n",
    "\n",
    "How do you think they will compare to the rates we see at our location in Stockholm, Sweden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotComparisonHistograms('DoseNet measurements',cpm_etch,'Berkeley, CA',cpm_jp,'Koriyama City, Japan',cpm_norra,'Stockholm, Sweden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the rates at these locations statistically different? How could we quantify this comparison?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etch_mean = np.mean(cpm_etch)\n",
    "etch_sigma = np.sqrt(np.var(cpm_etch))\n",
    "jp_mean = np.mean(cpm_jp)\n",
    "jp_sigma = np.sqrt(np.var(cpm_jp))\n",
    "norra_mean = np.mean(cpm_norra)\n",
    "norra_sigma = np.sqrt(np.var(cpm_norra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Average count-rate in Berkeley = {0:.2g} +/- {1:.2g}'.format(etch_mean,etch_sigma))\n",
    "print('Average count-rate in Koriyama City = {0:.2g} +/- {1:.2g}'.format(jp_mean,jp_sigma))\n",
    "print('Average count-rate in Stockholm = {0:.2g} +/- {1:.2g}'.format(norra_mean,norra_sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at how the rates at each station vary over the course of a month in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = dateutil.parser.parse('2017-5-20')\n",
    "stop_time = dateutil.parser.parse('2017-6-20')\n",
    "tdelta = dt.timedelta(hours=8)\n",
    "month_etch, month_etch_times = SelectDataTimeRange(start_time,stop_time,cpm_etch,datetime_etch)\n",
    "month_etch, etch_errs, month_etch_times = GetMergedData(start_time,stop_time,month_etch,month_etch_times,tdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PlotWithErrors(month_etch, etch_errs, month_etch_times, 'Etcheverry DoseNet Measurements vs Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_jp, month_jp_times = SelectDataTimeRange(start_time,stop_time,cpm_jp,datetime_jp)\n",
    "month_jp, jp_errs, month_jp_times = GetMergedData(start_time,stop_time,month_jp,month_jp_times,tdelta)\n",
    "\n",
    "month_norra, month_norra_times = SelectDataTimeRange(start_time,stop_time,cpm_norra,datetime_norra)\n",
    "month_norra, norra_errs, month_norra_times = GetMergedData(start_time,stop_time,month_norra,month_norra_times,tdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PlotWithErrors(month_jp, jp_errs, month_jp_times, 'Koriyama City DoseNet Measurements vs Time')\n",
    "PlotWithErrors(month_norra, norra_errs, month_norra_times, 'Koriyama City DoseNet Measurements vs Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there statistically significant variations over time? Are the variations correlated from one station to another? \n",
    "\n",
    "Let's check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorrelation(month_etch,etch_errs,month_jp,jp_errs,'Berkeley CPM','Koriyama CPM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking beyond basic measurements of rates\n",
    "We monitor the rates for several naturally occurring and man-made sources of radiation present in the atmosphere using an air filtration system coupled with a high-purity Germanium detector. \n",
    "\n",
    "The rates for the most commonly occurring natural sources, uranium (Bi-214) and potassium (K-40) are plotted below together with man-made sources (Cs-134, Cs-137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time, Bi-214, K-40, Cs-134, Cs-137\n",
      "collected data between 2017-06-05 10:00:35 and 2017-06-21 12:42:55\n"
     ]
    }
   ],
   "source": [
    "# import data from air monitor for all isotopes\n",
    "date = []\n",
    "Bi214 = []\n",
    "Bi_err = []\n",
    "K40 = []\n",
    "K_err = []\n",
    "Cs134 = []\n",
    "Cs4_err = []\n",
    "Cs137 = []\n",
    "Cs7_err = []\n",
    "line = 0\n",
    "url = 'https://radwatch.berkeley.edu/sites/default/files/pictures/rooftop_tmp/weather.csv'\n",
    "response = urlopen(url)\n",
    "\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "for row in reader:\n",
    "    # skip meta-data\n",
    "    if line == 0:\n",
    "        print('')\n",
    "        print(\"Time, Bi-214, K-40, Cs-134, Cs-137\")\n",
    "    else:\n",
    "        date.append(dt.datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S'))\n",
    "        Bi214.append(float(row[1]))\n",
    "        Bi_err.append(float(row[2]))\n",
    "        K40.append(float(row[3]))\n",
    "        K_err.append(float(row[4]))\n",
    "        Cs134.append(float(row[5]))\n",
    "        Cs4_err.append(float(row[6]))\n",
    "        Cs137.append(float(row[7]))\n",
    "        Cs7_err.append(float(row[8]))\n",
    "    line += 1\n",
    "\n",
    "print('collected data between {} and {}'.format(date[0],date[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot isotope data together\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(date, Bi214, 'bo-', label=\"Bi-214\")\n",
    "ax.errorbar(date, Bi214, yerr=Bi_err, fmt='bo', ecolor='b')\n",
    "ax.plot(date, K40, 'rs-', label=\"K-40\")\n",
    "ax.errorbar(date, K40, yerr=K_err, fmt='rs-', ecolor='r')\n",
    "ax.plot(date, Cs134, 'g^-', label=\"Cs-134\")\n",
    "ax.errorbar(date, Cs134, yerr=Cs4_err, fmt='g^-', ecolor='g')\n",
    "ax.plot(date, Cs137, 'mv-', label=\"C-137\")\n",
    "ax.errorbar(date, Cs137, yerr=Cs7_err, fmt='mv-', ecolor='m')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc=2)\n",
    "#ax.set_yscale(\"log\", nonposy='clip')\n",
    "\n",
    "# format the ticks\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax.xaxis.set_minor_locator(mdates.HourLocator())\n",
    "\n",
    "# set x-axis scale and display format\n",
    "ax.set_xlim(date[0], date[-1])\n",
    "ax.fmt_xdata = mdates.DateFormatter('%Y-%m-%d %H:%M:%S')\n",
    "# rotates and right aligns the x labels\n",
    "# moves the bottom of the axes up to make room for them\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.ylabel('counts-per-second')\n",
    "plt.xlabel('Time')\n",
    "plt.title('CPS over time for different isotopes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at whether the rates for various isotopes are correlated, do you expect to see a correlation? Which isotopes might be correlated and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorrelation(Bi214,Bi_err,K40,K_err,'Bi-214 cps','K-40 cps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating radiation to the environment\n",
    "\n",
    "Finally, we can look at how radiation rates might be affected by other environmental factors, such as temperature or rainfall.\n",
    "\n",
    "First, we can collect weather data from weather stations in proximity to our detectors in Berkeley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data from weather station\n",
    "start = ['8','27','2017']\n",
    "location = 'KCABERKE95'\n",
    "data = GetWeatherData(location, start)\n",
    "\n",
    "date, temperature, pressure, humidity, hourPrecep = GetWeatherStationData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PlotData(date,temperature,'T vs Time','Temperatuer (C)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look for correlations between the rate of radiation and various environmental factors, such as temperature. \n",
    "\n",
    "Why might radiation levels vary with temperature, what about rainfall? \n",
    "\n",
    "What other environmental factors might affect background radiation levels and how could we measure them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wtimes, temps, t_errs = GetWeatherDataRange(location,8,start_time,stop_time,'Temp')\n",
    "wtimes, hums, h_errs = GetWeatherDataRange(location,8,start_time,stop_time,'Humid')\n",
    "wtimes, rads, s_errs = GetWeatherDataRange(location,8,start_time,stop_time,'Rad')\n",
    "wtimes, rains, r_errs = GetWeatherDataRange(location,8,start_time,stop_time,'Rain')\n",
    "wtimes, press, p_errs = GetWeatherDataRange(location,8,start_time,stop_time,'Press')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorrelation(temps,t_errs,rads,s_errs,'Local Temp (C)','Solar Radiation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorrelation(month_etch,etch_errs,temps,t_errs,'Berkeley CPM','Local Temp (C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorrelation(month_etch,etch_errs,hums,h_errs,'Berkeley CPM','Humidity (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A first look at quantifying the correlation\n",
    "month_etch_clean = [value for value in month_etch if not math.isnan(value)]\n",
    "hums_clean = [value for value in hums if not math.isnan(value)]\n",
    "while len(hums_clean) > len(month_etch_clean):\n",
    "    hums_clean.pop()\n",
    "while len(hums_clean) < len(month_etch_clean):\n",
    "    month_etch_clean.pop()\n",
    "\n",
    "a = pearsonr(month_etch_clean, hums_clean)\n",
    "#print(\"Pearson r =\", a[0])\n",
    "#print(\"P value =\", a[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
